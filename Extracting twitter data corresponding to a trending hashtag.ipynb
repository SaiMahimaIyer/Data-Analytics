{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Twitter API credentials\n",
    "\n",
    "\n",
    "\n",
    "consumer_key = 'xxxxxxxxxxxx'\n",
    "consumer_secret = 'yyyyyyyyyyyyyyyy'\n",
    "access_key = 'zzzzzzzzzzzzzzzzzzzzzzzzzz'\n",
    "access_secret = 'aaaaaaaaaaaaaaaaaaaaaaa'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass twitter credentials to tweepy\n",
    "import tweepy\n",
    "# Create the api endpoint\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of tweets that you want to extract- 5\n"
     ]
    }
   ],
   "source": [
    "# Mention the maximum number of tweets that you want to be extracted.\n",
    "\n",
    "#I used the hashtag â€“ python and gave 500 as maximum number of tweets to be extracted if found. \n",
    "\n",
    "maximum_number_of_tweets_to_be_extracted = \\\n",
    "int(input('Enter the number of tweets that you want to extract- '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the hashtag you want to scrape- python\n"
     ]
    }
   ],
   "source": [
    "# Mention the hashtag that you want to look out for\n",
    "\n",
    "hashtag = input('Enter the hashtag you want to scrape- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.search, q='#' + hashtag,rpp=100).items(maximum_number_of_tweets_to_be_extracted):\n",
    "    with open('tweets_with_hashtag_' + hashtag + '1.txt', 'a') as the_file:\n",
    "        the_file.write(str(tweet.text.encode('utf-8')) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 5 tweets with hashtag #python\n"
     ]
    }
   ],
   "source": [
    "print ('Extracted ' + str(maximum_number_of_tweets_to_be_extracted) \\\n",
    "+ ' tweets with hashtag #' + hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'RT @takamina52: python\\xe3\\x83\\x97\\xe3\\x83\\xad\\xe3\\x82\\xb0\\xe3\\x83\\xa9\\xe3\\x83\\x9f\\xe3\\x83\\xb3\\xe3\\x82\\xb0\\xe3\\x83\\x96\\xe3\\x83\\xad\\xe3\\x82\\xb0\\xe3\\x82\\x92\\xe5\\xa7\\x8b\\xe3\\x82\\x81\\xe3\\x81\\xbe\\xe3\\x81\\x97\\xe3\\x81\\x9f\\xe3\\x80\\x82\\n\\xe3\\x82\\x86\\xe3\\x82\\x8b\\xef\\xbd\\x9e\\xe3\\x81\\x8f\\xe3\\x80\\x81\\xe3\\x82\\x84\\xe3\\x81\\xa3\\xe3\\x81\\xa6\\xe3\\x81\\x84\\xe3\\x81\\x8d\\xe3\\x81\\xbe\\xe3\\x81\\x99\\xe3\\x81\\xae\\xe3\\x81\\xa7\\xe3\\x80\\x81\\xe3\\x83\\x97\\xe3\\x83\\xad\\xe3\\x82\\xb0\\xe3\\x83\\xa9\\xe3\\x83\\x9f\\xe3\\x83\\xb3\\xe3\\x82\\xb0\\xe3\\x82\\x92\\xe5\\xa7\\x8b\\xe3\\x82\\x81\\xe3\\x81\\xa6\\xe3\\x81\\xbf\\xe3\\x81\\x9f\\xe3\\x81\\x84\\xe6\\x96\\xb9\\xe3\\x82\\x84\\xe3\\x80\\x81\\xe4\\xbb\\x96\\xe3\\x81\\xae\\xe3\\x83\\x97\\xe3\\x83\\xad\\xe3\\x82\\xb0\\xe3\\x83\\xa9\\xe3\\x83\\x9f\\xe3\\x83\\xb3\\xe3\\x82\\xb0\\xe8\\xa8\\x80\\xe8\\xaa\\x9e\\xe3\\x81\\xab\\xe8\\xa7\\xa6\\xe3\\x82\\x8c\\xe3\\x81\\xa6\\xe8\\xa6\\x8b\\xe3\\x81\\x9f\\xe3\\x81\\x84\\xe6\\x96\\xb9\\xe3\\x81\\xaf\\xe3\\x80\\x81\\xe6\\x98\\xaf\\xe9\\x9d\\x9e\\xe3\\x81\\x94\\xe8\\xa6\\xa7\\xe3\\x81\\x8f\\xe3\\x81\\xa0\\xe3\\x81\\x95\\xe3\\x81\\x84\\xe2\\x9c\\xa8\\n\\n#\\xe3\\x83\\x97\\xe3\\x83\\xad\\xe3\\x82\\xb0\\xe3\\x83\\xa9\\xe3\\x83\\x9f\\xe3\\x83\\xb3\\xe3\\x82\\xb0\\n#python'\n",
      "b\"RT @panopta: We're excited to host this week's @ChicagoPython event! Hear from three great speakers, including Panopta's own @jasonabate, a\\xe2\\x80\\xa6\"\n",
      "b'RT @Biff_Bruise: \\xe2\\x80\\xa2 What baseball can teach you about using data to improve yourself \\xe2\\x80\\xa6 so when do we get our own personal version of WAR? \\xf0\\x9f\\x98\\x81\\xe2\\x80\\xa6'\n",
      "b'RT @Ronald_vanLoon: 60+ Free Books on #BigData, #DataScience, #DataMining, #MachineLearning, #Python, R, and more \\nby @_Brendan_Martin @gho\\xe2\\x80\\xa6'\n",
      "b'RT @DataScientistFr: Python Machine Learning Cookbook - 2nd Edition: Over 100 Recipes. #BigData #Analytics #DataScience #AI #MachineLearnin\\xe2\\x80\\xa6'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f=open('tweets_with_hashtag_' + hashtag + '1.txt', 'r')\n",
    "contents =f.read()\n",
    "print(contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
